#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Author: Mara Alexandru Cristian
# Contact: alexandru.mara@ugent.be
# Date: 18/12/2018

# This code generates train/test splits of edges from input graphs for evaluating graph embeddings   
# on link prediction. It also provides false train and test edge sets of the required sizes.

# The train/test sets are efficiently generated by: i) obtaining a spanning tree of the input graph
# selected uniformly at random. ii) adding more edges to the spanning tree until the required amount
# of train edges is reached.

from __future__ import division
from __future__ import print_function

import random
import warnings

import networkx as nx
import numpy as np
from sklearn.externals.joblib import Parallel, delayed


def _sanity_check(G):
    r"""
    Helper function that checks if the input graphs contains a single connected component. Raises an error if not.

    Parameters
    ----------
    G : graph
       A NetworkX graph
    """
    # Compute the number of connected components
    if G.is_directed():
        num_ccs = nx.number_weakly_connected_components(G)
    else:
        num_ccs = nx.number_connected_components(G)

    # Rise an error if more than one CC exists
    if num_ccs != 1:
        raise ValueError("Input graph should contain one (weakly) connected component. "
                         "This graph contains: " + str(num_ccs))


def _broder_alg(G, E):
    r"""
    Runs Andrei Broder's algorithm to select uniformly at random a spanning tree of the input
    graph. G is undirected, but, the direction of the edges included in train_E is taken from E
    thus, the results are still valid for directed graphs.
    Ref: www.cs.cmu.edu/~15859n/RelatedWork/Broder-GenRanSpanningTrees.pdf

    Parameters
    ----------
    G : graph
       A NetworkX graph
    E : set
       A set of directed or undirected edges constituting the graph G.

    Returns
    -------
    train_E : set
       A set of edges of G describing the random spanning tree
    """
    # Create two partitions, S and T. Initially store all nodes in S.
    S = set(G.nodes)
    T = set()

    # Pick a random node as the "current node" and mark it as visited.
    current_node = random.sample(S, 1).pop()
    S.remove(current_node)
    T.add(current_node)

    # Perform random walk on the graph
    train_E = set()
    while S:
        neighbour_node = random.sample(list(G.neighbors(current_node)), 1).pop()
        if neighbour_node not in T:
            S.remove(neighbour_node)
            T.add(neighbour_node)
            if (current_node, neighbour_node) in E:
                train_E.add((current_node, neighbour_node))
            else:
                train_E.add((neighbour_node, current_node))
        current_node = neighbour_node

    # Return the set of edges constituting the spanning tree
    return train_E


def _compute_one_split(G, output_path, owa=True, train_frac=0.51, num_fe_train=None, num_fe_test=None, split_id=0):
    r"""
    Computes one split of train/test edges as well as non-edges from an input graph and writes the data to files.
    The train sets are always connected / weakly connected and span all nodes of the input graph.
    Input graphs (digraphs) cannot contain more than one (weakly) connected component.

    Parameters
    ----------
    G : graph
       A NetworkX graph
    output_path : string
       Indicates the path where data will be stored. Can include a name for all splits to share.
    owa : bool, optional
       Encodes the belief that the network respects or not the open world assumption. Default is True.
       If OWA=True, false train edges can be true test edges. False edges sampled from train graph.
       If OWA=False, closed world is assumed so false train edges are known to be false (not in G)
    train_frac : float, optional
       The relative size (in range (0.0, 1.0]) of the train set with respect to the total number of edges in the graph.
       Default is 0.51.
    num_fe_train : int, optional
       The number of train false edges to generate. Default is same number as true train edges.
    num_fe_test : int, optional
       The number of test false edges to generate. Default is same number as true test edges.
    split_id : int, optional
        The ID of train/test split. Default is 0.
    """
    # Generate train and test edge splits
    train_E, test_E = split_train_test(G, train_frac)

    # Generate the train/test false edges
    if owa:
        train_E_false, test_E_false = generate_false_edges_owa(G, train_E, test_E, num_fe_train, num_fe_test)
    else:
        train_E_false, test_E_false = generate_false_edges_cwa(G, train_E, test_E, num_fe_train, num_fe_test)

    #  Write the computed split to a file
    store_train_test_splits(output_path, train_E, train_E_false, test_E, test_E_false, split_id)


def compute_splits_parallel(G, output_path, owa=True, train_frac=0.51, num_fe_train=None, num_fe_test=None,
                            num_splits=10):
    r"""
    Computes in parallel the required number of train/test splits of edges and non-edges from an input graph
    and writes the data to files. The train sets are always connected / weakly connected and span all nodes
    of the input graph. Input graphs (digraphs) cannot contain more than one (weakly) connected component.
    
    Parameters
    ----------
    G : graph
       A NetworkX graph
    output_path : string
       Indicates the path where data will be stored. Can include a name for all splits to share.  
    owa : bool, optional
       Encodes the belief that the network respects or not the open world assumption. Default is True.
       If OWA=True, false train edges can be true test edges. False edges sampled from train graph. 
       If OWA=False, closed world is assumed so false train edges are known to be false (not in G)
    train_frac : float, optional
       The relative size (in range (0.0, 1.0]) of the train set with respect to the total number of edges in the graph.
       Default is 0.51.
    num_fe_train : int, optional
       The number of train false edges to generate. Default is same number as true train edges.
    num_fe_test : int, optional
       The number of test false edges to generate. Default is same number as true test edges.
    num_splits : int, optional
       The number of train/test splits to generate. Default is 10.
    """
    # Compute the splits sequentially or in parallel
    backend = 'multiprocessing'
    path_func = delayed(_compute_one_split)
    Parallel(n_jobs=num_splits, verbose=True, backend=backend)(
        path_func(G, output_path, owa, train_frac, num_fe_train, num_fe_test, split) for split in range(num_splits))


def split_train_test(G, train_frac=0.51):
    r"""
    Computes one train/test split of edges from an input graph and returns the results.
    The train set will be (weakly) connected and span all nodes of the input graph.
    Input graph (digraph) cannot contain more than one (weakly) connected component.
    
    Parameters
    ----------
    G : graph
       A NetworkX graph
    train_frac : float, optional
       The relative size (in range (0.0, 1.0]) of the train set with respect to the total number of edges in the graph.
       Default is 0.51.

    Returns
    -------
    train_E : set
       The set of train edges
    test_E : set
       The set of test edges
    """
    # Sanity check to make sure the input is correct
    _sanity_check(G)
    if train_frac <= 0.0 or train_frac > 1.0:
        raise ValueError('The train_frac parameter needs to be in range: (0.0, 1.0]')

    # Create a set of all edges in G
    E = set(G.edges)

    # Make the input graph is undirected in order to compute the random spanning tree
    # The set of all edges E still contains the direction of edges
    H = nx.to_undirected(G)

    # Compute a random spanning tree using broder's algorithm
    train_E = _broder_alg(H, E)

    # Fill test edge set as all edges not in the spanning tree
    test_E = E - train_E

    # Compute num train edges
    num_E = len(E)
    num_train_E = np.ceil(train_frac * num_E)

    # Check if the num edges in the spanning tree is already greater than the num train edges
    num_toadd = int(num_train_E - len(train_E))
    if num_toadd <= 0:
        print("WARNING: In order to return a connected train set the train_frac parameter needs to be higher!")
        print("In this case, the provided train set constitutes a random spanning tree of the input graph.")
        print("The train_frac value used is: {}".format(len(train_E) / num_E))
        print("Edges requested: train = {}, test = {}".format(num_train_E, num_E - num_train_E))
        print("Edges returned: train = {}, test = {}".format(len(train_E), num_E - len(train_E)))
    else:
        # Add more edges to train set from test set until it has deseired size
        edges = set(random.sample(test_E, num_toadd))
        test_E = test_E - edges
        train_E = train_E | edges

    # Perform some simple checks
    assert E == (test_E | train_E)
    assert len(E) == len(test_E) + len(train_E)
    if num_toadd > 0:
        assert num_train_E == len(train_E)

    # Return the sets of edges
    return train_E, test_E


def naive_split_train_test(G, train_frac=0.51):
    r"""
    Computes one train/test split of edges from an input graph and returns the results.
    The sets are computed using the naive approach that checks connectivity of the graph
    for each removed edge. If graph gets disconnected, that edges is not removed.
    The train set will be (weakly) connected and span all nodes of the input graph.
    Input graph (digraph) cannot contain more than one (weakly) connected component.

    Parameters
    ----------
    G : graph
      A NetworkX graph
    train_frac : float, optional
        The relative size (in range (0.0, 1.0]) of the train set with respect to the total number of edges in the graph.
        Default is 0.51.

    Returns
    -------
    train_E : set
       The set of train edges
    test_E : set
        The set of test edges
    """
    # Sanity check to make sure the input is correct
    _sanity_check(G)
    if train_frac <= 0.0 or train_frac > 1.0:
        raise ValueError('The train_frac parameter needs to be in range: (0.0, 1.0]')

    # Is directed
    directed = G.is_directed()

    G = G.copy()

    # Create a set of all edges in G
    aux = np.array(G.edges)
    np.random.shuffle(aux)
    E = set([tuple(edge) for edge in aux])

    # Compute num train edges
    num_E = len(E)
    num_train_E = np.ceil(train_frac * num_E)
    num_test_E = num_E - num_train_E

    # Initialize train edges to an empty set
    train_E = set(G.edges())

    # Initialize test edges to an empty set
    test_E = set()

    # Iterate over shuffled edges, add to train/val sets

    for i, edge in enumerate(E):
        # if i % 500 == 0:
        #    print('{}/{}'.format(i, num_test_E))
        node1 = edge[0]
        node2 = edge[1]

        # If removing edge would disconnect a connected component, backtrack and move on
        G.remove_edge(node1, node2)
        if directed:
            if nx.number_weakly_connected_components(G) > 1:
                G.add_edge(node1, node2)
                continue
        else:
            if nx.number_connected_components(G) > 1:
                G.add_edge(node1, node2)
                continue

        # Fill test_edges
        if len(test_E) < num_test_E:
            test_E.add(edge)
            train_E.remove(edge)
        else:
            break

    # Perform some simple checks
    assert E == (test_E | train_E)
    assert len(E) == len(train_E) + len(test_E)

    # Return the sets of edges
    return train_E, test_E


def generate_false_edges_owa(G, train_E, test_E, num_fe_train=None, num_fe_test=None):
    r"""
    This method generates false train and test edges for both directed and undirected graphs.
    The train and test sets are non overlapping.
    Follows the open world assumption, so false train edges are generated only using the true train edges,
    so false train edges can be true test edges. This is the case for evolving graphs where edges can only appear.
    For undirected graphs the output is sorted (smallNodeID, bigNodeID)

    Parameters
    ----------
    G : graph
       A NetworkX graph
    train_E : set
       The set of train edges.
    test_E : set
       The set of test edges.
    num_fe_train : int, optional
       The number of train false edges to generate. Default is same number as true train edges.
    num_fe_test : int, optional
       The number of test false edges to generate. Default is same number as true test edges.

    Returns
    -------
    train_false_E : set
       The set of false train edges
    test_false_E : set
       The set of false test edges
    """
    # Sanity check to make sure the input is correct
    _sanity_check(G)

    # Create a set of vertices
    V = set(G.nodes)

    # Initialize the sizes of the false edges
    if num_fe_train is None:
        num_fe_train = len(train_E)

    if num_fe_test is None:
        num_fe_test = len(test_E)

    # Make sure the required amount of false edges can be generated
    max_nonedges = len(V) * len(V) - len(G.edges)
    if num_fe_train > max_nonedges:
        raise ValueError('Too many false train edges required! Max available for train+test is {}'.format(max_nonedges))
    else:
        if num_fe_train + num_fe_test > max_nonedges:
            warnings.warn('Too many false edges required in train+test! '
                          'Using maximum number of false test edges available: {}'.format(max_nonedges - num_fe_train))
            num_fe_test = max_nonedges - num_fe_train

    # Create sets to store the false edges
    train_E_false = set()
    test_E_false = set()

    # Generate negative train edges
    while len(train_E_false) < num_fe_train:
        edge = tuple(random.sample(V, 2))
        redge = tuple(reversed(edge))
        if edge not in train_E:
            if G.is_directed():
                train_E_false.add(edge)
            else:
                if redge not in train_E:
                    train_E_false.add(tuple(sorted(edge)))

    # Generate negative test edges
    while len(test_E_false) < num_fe_test:
        edge = tuple(random.sample(V, 2))
        redge = tuple(reversed(edge))
        if edge not in train_E and edge not in test_E and edge not in train_E_false:
            if G.is_directed():
                test_E_false.add(edge)
            else:
                if redge not in train_E and redge not in test_E and redge not in train_E_false:
                    test_E_false.add(tuple(sorted(edge)))

    # Perform some simple check before returning the result
    assert len(train_E_false) == num_fe_train
    assert len(test_E_false) == num_fe_test
    assert train_E_false.isdisjoint(test_E_false)
    assert train_E_false.isdisjoint(train_E)
    assert test_E_false.isdisjoint(train_E | test_E)

    # Return the sets of false edges
    return train_E_false, test_E_false


def generate_false_edges_cwa(G, train_E, test_E, num_fe_train=None, num_fe_test=None):
    r"""
    This method generates false train and test edges for both directed and undirected graphs.
    The train and test sets are non overlapping.
    Follows the closed world assumption, so false train edges are selected as known to be false.
    This is the case for some networks e.g. protein-protein interaction where information about
    both the positive class (existing edges) and the negative class (missing edges) exists.
    For undirected graphs the output is sorted (smallNodeID, bigNodeID)

    Parameters
    ----------
    G : graph
       A NetworkX graph
    train_E : set
       The set of train edges.
    test_E : set
       The set of test edges.
    num_fe_train : int, optional
       The number of train false edges to generate. Default is same number as true train edges.
    num_fe_test : int, optional
       The number of test false edges to generate. Default is same number as true test edges.

    Returns
    -------
    train_false_E : set
       The set of false train edges
    test_false_E : set
       The set of false test edges
    """
    # Sanity check to make sure the input is correct
    _sanity_check(G)

    # Create a set of vertices
    V = set(G.nodes)

    # Initialize the sizes of the false edges
    if num_fe_train is None:
        num_fe_train = len(train_E)

    if num_fe_test is None:
        num_fe_test = len(test_E)

    # Make sure the required amount of false edges can be generated
    max_nonedges = len(V) * len(V) - len(G.edges)
    if num_fe_train > max_nonedges:
        raise ValueError(
            'Too many false train edges required! Max available for train+test is {}'.format(max_nonedges))
    else:
        if num_fe_train + num_fe_test > max_nonedges:
            warnings.warn('Too many false edges required in train+test! '
                          'Using maximum number of false test edges available: {}'.format(max_nonedges - num_fe_train))
            # num_fe_test = max_nonedges - num_fe_train
            return _getall_false_edges(G, (1.0*num_fe_train)/max_nonedges)

    # Create sets to store the false edges
    train_E_false = set()
    test_E_false = set()

    # Generate negative train edges
    while len(train_E_false) < num_fe_train:
        edge = tuple(random.sample(V, 2))
        redge = tuple(reversed(edge))
        if edge not in train_E and edge not in test_E:
            if G.is_directed():
                train_E_false.add(edge)
            else:
                if redge not in train_E and redge not in test_E:
                    train_E_false.add(tuple(sorted(edge)))

    # Generate negative test edges
    while len(test_E_false) < num_fe_test:
        edge = tuple(random.sample(V, 2))
        redge = tuple(reversed(edge))
        if edge not in train_E and edge not in test_E and edge not in train_E_false:
            if G.is_directed():
                test_E_false.add(edge)
            else:
                if redge not in train_E and redge not in test_E and redge not in train_E_false:
                    test_E_false.add(tuple(sorted(edge)))

    # Perform some simple check before returning the result
    assert len(train_E_false) == num_fe_train
    assert len(test_E_false) == num_fe_test
    assert train_E_false.isdisjoint(test_E_false)
    assert train_E_false.isdisjoint(train_E | test_E)
    assert test_E_false.isdisjoint(train_E | test_E)

    # Return the sets of false edges
    return train_E_false, test_E_false


def _getall_false_edges(G, fe_train_frac):
    print("Generating all non-edges and splitting them in train and test...")
    train_E_false = list()
    test_E_false = list()
    for e in nx.non_edges(G):
        r = random.uniform(0, 1)
        if r <= fe_train_frac:
            train_E_false.append(e)
        else:
            test_E_false.append(e)

    return train_E_false, test_E_false


def redges_false(train_E, test_E, output_path=None):
    r"""
    For directed graphs computes all non-edges (a->b) such that the opposite edge (a<-b) exists in the graph.
    It does this for both the train and test edge sets. These non-edges can be used to asses the performance
    of the embedding methods on predicting non-reciprocated edges.

    Parameters
    ----------
    train_E : set
       The set of train edges.
    test_E : set
       The set of test edges.
    output_path : string, optional
        A path or file where to store the results. Default None.

    Returns
    -------
    train_redges_false : set
        A set of edges respecting the mentioned property regarding the train edges
    test_redges_false : set
        A set of edges respecting the mentioned property on the complete graph
    """
    # Reverse all train and test edges
    train_redges_false = set(tuple(reversed(edge_tuple)) for edge_tuple in train_E)
    test_redges_false = set(tuple(reversed(edge_tuple)) for edge_tuple in test_E)

    # Keep only the reversed edges which are not real train edges
    train_redges_false = train_redges_false - train_E

    # Keep only the test reversed edges which are not true edges in the graph
    test_redges_false = test_redges_false - train_E
    test_redges_false = test_redges_false - test_E

    if output_path is not None:
        # Store the reversed edges
        train_redges_false_np = np.array([list(edge_tuple) for edge_tuple in train_redges_false])
        test_redges_false_np = np.array([list(edge_tuple) for edge_tuple in test_redges_false])
        # Save the splits in different files
        np.savetxt(output_path, train_redges_false_np, delimiter=',', fmt='%d')
        np.savetxt(output_path, test_redges_false_np, delimiter=',', fmt='%d')

    # Return the computed sets
    return train_redges_false, test_redges_false


def store_train_test_splits(output_path, train_E, train_E_false, test_E, test_E_false, split_id=0):
    r"""
    Writes the sets of true and false edges to files in the provided path. All files will share
    the same split number as an identifier.
    
    Parameters
    ----------
    output_path : string
       Indicates the path where data will be stored. It can also include a name for all the splits to share.
    train_E : set
       Set of train edges
    train_E_false : set
       Set of train non-edges
    test_E : set
       Set of test edges
    test_E_false : set
       Set of test non-edges
    split_id : int, optional
       The ID of train/test split to be stored. Default is 0.

    Returns
    -------
    filenames : list
        A list of strings, the names given to the 4 files where the true and false train and test edge are stored.
    """
    # Convert edge-lists to numpy arrays
    train_E = np.array([list(edge_tuple) for edge_tuple in train_E])
    train_E_false = np.array([list(edge_tuple) for edge_tuple in train_E_false])
    test_E = np.array([list(edge_tuple) for edge_tuple in test_E])
    test_E_false = np.array([list(edge_tuple) for edge_tuple in test_E_false])

    filenames = ("{}_trE_{}.csv".format(output_path, split_id), "{}_negTrE_{}.csv".format(output_path, split_id),
                 "{}_teE_{}.csv".format(output_path, split_id), "{}_negTeE_{}.csv".format(output_path, split_id))

    # Save the splits in different files
    np.savetxt(fname=filenames[0], X=train_E, delimiter=',', fmt='%d')
    np.savetxt(fname=filenames[1], X=train_E_false, delimiter=',', fmt='%d')
    np.savetxt(fname=filenames[2], X=test_E, delimiter=',', fmt='%d')
    np.savetxt(fname=filenames[3], X=test_E_false, delimiter=',', fmt='%d')

    # Return the names given to the 4 files where data is stored
    return filenames


def store_edgelists(train_path, test_path, train_edges, test_edges):
    r"""
    Writes the train and test edgelists to files with the specified names.

    Parameters
    ----------
    train_path : string
       Indicates the path where the train data will be stored.
    test_path : string
       Indicates the path where the test data will be stored.
    train_edges : array_like
       Set of train true and false edges
    test_edges : array_like
       Set of test true and false edges
    """
    # Convert edge-lists to numpy arrays
    train_edges = np.array([list(edge_tuple) for edge_tuple in train_edges])
    test_edges = np.array([list(edge_tuple) for edge_tuple in test_edges])

    # Save the splits in different files
    np.savetxt(fname=train_path, X=train_edges, delimiter=',', fmt='%d')
    np.savetxt(fname=test_path, X=test_edges, delimiter=',', fmt='%d')


def check_overlap(filename, num_sets):
    r"""
    Shows the amount of overlap (shared elements) between edge sets from different random splits.
    The path and name of the set (without split ID) for which to compute the overlap is required. 
    The method will read num_sets from the same path and compute the overlap between them. 

    Parameters
    ----------
    filename : string
       Indicates the path and name (without split ID) of the first set.
       The sets are assumed to have sequential split IDs starting at 0. 
    num_sets : int
       The number of sets for which to check the overlap.
    """
    # Load the first set and transform it into a list of tuples
    S = np.loadtxt(filename+"_0.csv", delimiter=',', dtype=int)
    S = set(map(tuple, S))

    # Initialize the intersection and union sets as all elements in first edge set
    intrs = S
    union = S

    # Sequentially add the rest of the sets and check overlap
    for i in range(num_sets-1):
        # Read a new edge set
        S = np.loadtxt(filename+"_{}.csv".format(i+1), delimiter=',', dtype=int)
        S = set(map(tuple, S))
        # Update intersection and union sets
        intrs = intrs & S
        union = union | S
        # Print the information on screen
        print("Intersection of {} sets is {}".format(i+2, len(intrs)))
        print("Union of {} sets is {}".format(i+2, len(union)))
        print("Jaccard coefficient: {}".format(len(intrs)/len(union)))
        print("")
